{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Enriching Data**\n",
    "\n",
    "After the _very_ messy Notebook 4, I've got a list of different games. Within this notebook, I aim to use the new Web Search tool & the OpenAI Responses API to grab additional information about each game.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "The cells below will help to set up the rest of the notebook.\n",
    "\n",
    "I'll start by configuring the kernel that's running this notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the cwd\n",
    "%cd ..\n",
    "\n",
    "# Enable the autoreload module\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load the environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'm going to import the necessary modules:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import time\n",
    "from typing import List, Optional\n",
    "import hashlib\n",
    "\n",
    "# Third-party imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from Levenshtein import ratio as lev_ratio\n",
    "\n",
    "# Set up the OpenAI client\n",
    "openai_client = OpenAI()\n",
    "\n",
    "\n",
    "# Function to generate a consistent hash from text\n",
    "def get_consistent_hash(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a cryptographically stronger hash value from a string.\n",
    "\n",
    "    This implementation uses SHA-256 for better collision resistance\n",
    "    and more uniform distribution of hash values.\n",
    "\n",
    "    Args:\n",
    "        text: The input text to hash\n",
    "\n",
    "    Returns:\n",
    "        A consistent 12-character hash value as string\n",
    "    \"\"\"\n",
    "\n",
    "    # Use SHA-256 for better collision resistance\n",
    "    hash_obj = hashlib.sha256(text.encode(\"utf-8\"))\n",
    "    # Get hexadecimal digest and take first 12 characters\n",
    "    return hash_obj.hexdigest()[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "Below, I'm going to load in all of the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "playable_games_df = pd.read_json(\"data/unified_games_data.json\")\n",
    "\n",
    "# Drop all of the games that're missing a booth_number and/or exhibitor_name\n",
    "playable_games_df = playable_games_df[\n",
    "    playable_games_df[\"booth_number\"].notna()\n",
    "    & playable_games_df[\"exhibitor_name\"].notna()\n",
    "]\n",
    "\n",
    "# Add an ID to each of the games by hashing the name to a UUID\n",
    "playable_games_df[\"game_id\"] = playable_games_df[\"title\"].apply(\n",
    "    lambda x: get_consistent_hash(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this look like?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playable_games_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many are there?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(playable_games_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching the Web with OpenAI\n",
    "\n",
    "Next up: I'm going to try and use OpenAI's Responses API to search the web for more information about each game.\n",
    "\n",
    "I'll start by defining the developer prompt and output formats:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"# Role\n",
    "You're a digital assistant helping to identify information about games. \n",
    "\n",
    "# Task\n",
    "Search the Internet for information about games provided by users. Synthesize the game's name, description, genres, release date, platforms, and Steam page link.\n",
    "\n",
    "Return information about the search process, including visited URLs and a summary of your findings.\n",
    "\n",
    "# Guidelines\n",
    "- You MUST use the web search tool to find information about the game. \n",
    "- ONLY identify information about the specific game provided. \n",
    "- Use authoritative sources (e.g., Wikipedia, Steam, the game's official website) to gather information; include reviews / preview articles to understand more about the game.\n",
    "- Return None for the `game_info` field if you can't identify the specific game (or if you're unsure about the identification).\n",
    "- Some of these games may be in-development, so information could be limited; try your best!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class GameInfo(BaseModel):\n",
    "    game_name: str = Field(..., description=\"The name of the game.\")\n",
    "    released: bool = Field(\n",
    "        ..., description=\"Whether the game has been released (True) or not (False).\"\n",
    "    )\n",
    "    release_time: Optional[str] = Field(\n",
    "        ...,\n",
    "        description=\"A string describing the release date, with as much precision as is available.\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        ...,\n",
    "        description=\"A paragraph-long description summarizing gameplay, story, aesthetics, and unique features, written in Wikipedia style.\",\n",
    "    )\n",
    "    genres: Optional[List[str]] = Field(..., description=\"A list of genres\")\n",
    "    snappy_summary: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"A short, tagline-like summary (max 10 words) highlighting genre and unique appeal.\",\n",
    "    )\n",
    "    platforms: Optional[List[str]] = Field(\n",
    "        None,\n",
    "        description=\"Platforms available: PlayStation, Xbox, Nintendo Switch, PC, Mobile, or Tabletop\",\n",
    "    )\n",
    "    steam_link: Optional[str] = Field(\n",
    "        None, description=\"Direct URL to the game's Steam page.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class GameSearchResults(BaseModel):\n",
    "    web_search_summary: str = Field(\n",
    "        ..., description=\"Summary of whether platform and Steam info were found.\"\n",
    "    )\n",
    "    web_search_results: List[List[str]] = Field(\n",
    "        ...,\n",
    "        description=\"A list of all of the websites visited, where each tuple contains a webpage title and URL.\",\n",
    "    )\n",
    "    correctly_identified_game: bool = Field(\n",
    "        ..., description=\"Whether the game was correctly identified.\"\n",
    "    )\n",
    "    game_info: Optional[GameInfo] = Field(\n",
    "        None,\n",
    "        description=\"Found game info, if `correctly_identified_game` is True. Otherwise, None.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll iterate through each of the rows and get some information about them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_search_results_list = []\n",
    "for row in tqdm(\n",
    "    iterable=list(playable_games_df.itertuples()),\n",
    "    desc=\"Searching for game info\",\n",
    "):\n",
    "\n",
    "    # Grab the proper row description\n",
    "    game_descriptions = row.description_texts\n",
    "    game_descriptions_dict = {\n",
    "        desc.get(\"source\"): desc.get(\"text\") for desc in game_descriptions\n",
    "    }\n",
    "    game_description = (\n",
    "        game_descriptions_dict.get(\"pax_website\")\n",
    "        if \"pax_website\" in game_descriptions_dict\n",
    "        else (\n",
    "            game_descriptions_dict.get(\"pax_app\")\n",
    "            if \"pax_app\" in game_descriptions_dict\n",
    "            else \"Game Description Not Found\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"\"\"# **{row.title}**\n",
    "*{game_description}*\n",
    "\n",
    "**Developer:** {row.developer if pd.notna(row.developer) else \"Unknown\"}\n",
    "\n",
    "**Exhibitor:** {row.exhibitor_name if pd.notna(row.exhibitor_name) else \"Unknown\"}\n",
    "\n",
    "**Exhibitor Description:** {row.exhibitor_description if pd.notna(row.exhibitor_description) else \"Unknown\"}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai_client.responses.parse(\n",
    "            model=\"gpt-4.1\",\n",
    "            tools=[{\"type\": \"web_search_preview\", \"search_context_size\": \"high\"}],\n",
    "            input=[\n",
    "                {\n",
    "                    \"role\": \"developer\",\n",
    "                    \"content\": developer_prompt,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            text_format=GameSearchResults,\n",
    "            tool_choice={\"type\": \"web_search_preview\"},\n",
    "        )\n",
    "\n",
    "        # Add a response\n",
    "        cur_row_dict = {\n",
    "            \"game_id\": row.game_id,\n",
    "            \"web_search_summary\": response.output_parsed.web_search_summary,\n",
    "            \"web_search_results\": response.output_parsed.web_search_results,\n",
    "            \"correctly_identified_game\": response.output_parsed.correctly_identified_game,\n",
    "        } | (\n",
    "            response.output_parsed.game_info.model_dump()\n",
    "            if response.output_parsed.game_info\n",
    "            else {}\n",
    "        )\n",
    "\n",
    "        game_search_results_list.append(cur_row_dict)\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(e)\n",
    "\n",
    "        cur_row_dict = {\n",
    "            \"game_id\": row.game_id,\n",
    "            \"web_search_summary\": None,\n",
    "            \"web_search_results\": None,\n",
    "            \"correctly_identified_game\": False,\n",
    "        }\n",
    "\n",
    "# Make a DataFrame from the results\n",
    "game_search_results_df = pd.DataFrame.from_records(game_search_results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll save this data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the game_search_results_df to a JSON file\n",
    "game_search_results_df.to_json(\n",
    "    \"data/game_search_results.json\", orient=\"records\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want to reload it below, I can:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the game_search_results_df\n",
    "game_search_results_df = pd.read_json(\"data/game_search_results.json\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying Steam Links\n",
    "\n",
    "The OpenAI web search seems to be working well enough, but it's not perfect. Below, I'll verify each of the Steam links that were identified, and scrape more information from them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_steam_game_info(html_content: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts game information from Steam game page HTML.\n",
    "\n",
    "    Args:\n",
    "        html_content: The HTML content of the Steam game page as a string.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the extracted information:\n",
    "        - name: Name of the game (str)\n",
    "        - developer: Name of the game's developer (str)\n",
    "        - image_address: URL of the header image (str)\n",
    "        - description: Game description (str)\n",
    "        - tags: List of popular user-defined tags (List[str])\n",
    "        - video_link: URL of the first game trailer video (str)\n",
    "                       or None if no video is found.\n",
    "        - image_links: List of screenshot image URLs (List[str])\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    game_info = {\n",
    "        \"name\": None,\n",
    "        \"developer\": None,\n",
    "        \"image_address\": None,\n",
    "        \"description\": None,\n",
    "        \"tags\": [],\n",
    "        \"video_link\": None,\n",
    "        \"image_links\": [],  # Added this line\n",
    "    }\n",
    "\n",
    "    # --- Extract Name ---\n",
    "    name_tag = soup.find(\"div\", class_=\"apphub_AppName\")\n",
    "    if name_tag:\n",
    "        game_info[\"name\"] = name_tag.get_text(strip=True)\n",
    "    else:\n",
    "        # Fallback for potential structure changes\n",
    "        name_title_tag = soup.find(\"title\")\n",
    "        if name_title_tag:\n",
    "            # Extract from title like \"Super Cucumber on Steam\"\n",
    "            title_text = name_title_tag.get_text(strip=True)\n",
    "            if \" on Steam\" in title_text:\n",
    "                game_info[\"name\"] = title_text.replace(\" on Steam\", \"\").strip()\n",
    "\n",
    "    # --- Extract Developer ---\n",
    "    developer_div = soup.find(\"div\", id=\"developers_list\")\n",
    "    if developer_div:\n",
    "        developer_link = developer_div.find(\"a\")\n",
    "        if developer_link:\n",
    "            game_info[\"developer\"] = developer_link.get_text(strip=True)\n",
    "    else:\n",
    "        # Fallback: Look for the grid structure\n",
    "        dev_label = soup.find(\"div\", class_=\"grid_label\", string=\"Developer\")\n",
    "        if dev_label:\n",
    "            dev_content = dev_label.find_next_sibling(\"div\", class_=\"grid_content\")\n",
    "            if dev_content:\n",
    "                dev_link = dev_content.find(\"a\")\n",
    "                if dev_link:\n",
    "                    game_info[\"developer\"] = dev_link.get_text(strip=True)\n",
    "\n",
    "    # --- Extract Image Address ---\n",
    "    # Look for the main header image first\n",
    "    img_tag = soup.find(\"img\", class_=\"game_header_image_full\")\n",
    "    if img_tag and img_tag.get(\"src\"):\n",
    "        game_info[\"image_address\"] = img_tag[\"src\"]\n",
    "    else:\n",
    "        # Fallback: Look for Open Graph image meta tag\n",
    "        og_image_tag = soup.find(\"meta\", property=\"og:image\")\n",
    "        if og_image_tag and og_image_tag.get(\"content\"):\n",
    "            game_info[\"image_address\"] = og_image_tag[\"content\"]\n",
    "\n",
    "    # --- Extract Description ---\n",
    "    # Look for the meta description tag\n",
    "    desc_meta_tag = soup.find(\"meta\", {\"name\": \"Description\"})\n",
    "    if desc_meta_tag and desc_meta_tag.get(\"content\"):\n",
    "        game_info[\"description\"] = desc_meta_tag[\"content\"].strip()\n",
    "    else:\n",
    "        # Fallback: Look for Open Graph description meta tag\n",
    "        og_desc_tag = soup.find(\"meta\", property=\"og:description\")\n",
    "        if og_desc_tag and og_desc_tag.get(\"content\"):\n",
    "            game_info[\"description\"] = og_desc_tag[\"content\"].strip()\n",
    "        else:\n",
    "            # Fallback: Look for the short glance description snippet\n",
    "            snippet_tag = soup.find(\"div\", class_=\"game_description_snippet\")\n",
    "            if snippet_tag:\n",
    "                game_info[\"description\"] = snippet_tag.get_text(strip=True)\n",
    "\n",
    "    # --- Extract Tags ---\n",
    "    tags_container = soup.find(\"div\", class_=\"glance_tags popular_tags\")\n",
    "    if tags_container:\n",
    "        tag_elements = tags_container.find_all(\"a\", class_=\"app_tag\")\n",
    "        game_info[\"tags\"] = [\n",
    "            tag.get_text(strip=True) for tag in tag_elements[:3]\n",
    "        ]  # Get first 3 tags as requested\n",
    "\n",
    "    # --- Extract Video Link ---\n",
    "    # Find the first movie element\n",
    "    video_element = soup.find(\"div\", class_=\"highlight_movie\")\n",
    "    if video_element:\n",
    "        # Prefer webm, then mp4. Prefer HD if available.\n",
    "        # Check for webm HD first\n",
    "        webm_hd_src = video_element.get(\"data-webm-hd-source\")\n",
    "        if webm_hd_src:\n",
    "            game_info[\"video_link\"] = webm_hd_src\n",
    "        else:\n",
    "            # Then check for mp4 HD\n",
    "            mp4_hd_src = video_element.get(\"data-mp4-hd-source\")\n",
    "            if mp4_hd_src:\n",
    "                game_info[\"video_link\"] = mp4_hd_src\n",
    "            else:\n",
    "                # Then check for regular webm\n",
    "                webm_src = video_element.get(\"data-webm-source\")\n",
    "                if webm_src:\n",
    "                    game_info[\"video_link\"] = webm_src\n",
    "                else:\n",
    "                    # Finally check for regular mp4\n",
    "                    mp4_src = video_element.get(\"data-mp4-source\")\n",
    "                    if mp4_src:\n",
    "                        game_info[\"video_link\"] = mp4_src\n",
    "\n",
    "    # --- Extract Image Links ---\n",
    "    screenshot_elements = soup.find_all(\"a\", class_=\"highlight_screenshot_link\")\n",
    "    for element in screenshot_elements:\n",
    "        if element and element.get(\"href\"):\n",
    "            game_info[\"image_links\"].append(element[\"href\"])\n",
    "\n",
    "    return game_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this method in hand, I can iterate through each game and create a link:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_details_df_records = []\n",
    "for row in tqdm(\n",
    "    iterable=list(game_search_results_df.itertuples()),\n",
    "    desc=\"Searching for Steam game info\",\n",
    "):\n",
    "    if pd.isna(row.steam_link):\n",
    "        steam_details_df_records.append(\n",
    "            {\n",
    "                \"game_id\": row.game_id,\n",
    "            }\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Make a request to the Steam page\n",
    "        response = requests.get(row.steam_link, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            # Extract game information\n",
    "            game_info = extract_steam_game_info(response.text)\n",
    "            game_info[\"game_id\"] = row.game_id\n",
    "            steam_details_df_records.append(game_info)\n",
    "\n",
    "            # Sleep for a bit\n",
    "            time.sleep(3)\n",
    "        else:\n",
    "            print(\n",
    "                f\"Failed to fetch Steam page for game ID {row.game_id}: {response.status_code}\"\n",
    "            )\n",
    "            steam_details_df_records.append(\n",
    "                {\n",
    "                    \"game_id\": row.game_id,\n",
    "                }\n",
    "            )\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed for game ID {row.game_id}: {e}\")\n",
    "        steam_details_df_records.append(\n",
    "            {\n",
    "                \"game_id\": row.game_id,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Make a DataFrame from the results\n",
    "steam_details_df = pd.DataFrame.from_records(steam_details_df_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the steam_details_df records, we'll add a steam_url column if the game name associated with the ID is within\n",
    "# a certain Levenshtein distance of the name in the game_search_results_df\n",
    "verified_steam_details_df_records = []\n",
    "for row in steam_details_df.itertuples():\n",
    "\n",
    "    # Make a dictionary of the steam details\n",
    "    cur_row_dict = row._asdict()\n",
    "\n",
    "    # Grab the game ID\n",
    "    game_id = row.game_id\n",
    "\n",
    "    # Determine the row from the game_search_results_df\n",
    "    game_row = playable_games_df[playable_games_df[\"game_id\"] == game_id].iloc[0]\n",
    "    game_name = game_row.title\n",
    "    search_row = game_search_results_df[\n",
    "        game_search_results_df[\"game_id\"] == game_id\n",
    "    ].iloc[0]\n",
    "    steam_link = search_row.steam_link\n",
    "\n",
    "    # Check if the name is within a certain Levenshtein distance\n",
    "    if lev_ratio(row.name, game_name) > 0.8:\n",
    "\n",
    "        # Add the steam URL to the record\n",
    "        cur_row_dict[\"steam_url\"] = steam_link\n",
    "\n",
    "        verified_steam_details_df_records.append(cur_row_dict)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Make a DataFrame from the results\n",
    "verified_steam_details_df = pd.DataFrame.from_records(verified_steam_details_df_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this data look like?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_steam_details_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll save this data below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_steam_details_df.to_json(\n",
    "    \"data/steam_details.json\", orient=\"records\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want to reload it, I can:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the verified_steam_details_df\n",
    "verified_steam_details_df = pd.read_json(\n",
    "    \"data/steam_details.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling Final Data\n",
    "\n",
    "Now that I've created all of this information, I'm going to attempt to compile it all together. I'll start by loading in the proper `DataFrames`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the game_search_results_df\n",
    "game_search_results_df = pd.read_json(\"data/game_search_results.json\")\n",
    "verified_steam_details_df = pd.read_json(\n",
    "    \"data/steam_details.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'll move into the data compilation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some dictionaries mapping the game IDs to data\n",
    "game_search_results_dict = {\n",
    "    row.game_id: row._asdict()\n",
    "    for row in game_search_results_df.itertuples()\n",
    "    if row.correctly_identified_game\n",
    "}\n",
    "steam_details_dict = {\n",
    "    row.game_id: row._asdict() for row in verified_steam_details_df.itertuples()\n",
    "}\n",
    "original_games_dict = {\n",
    "    row.game_id: row._asdict() for row in playable_games_df.itertuples()\n",
    "}\n",
    "\n",
    "# Create a final_enriched_games_df DataFrame\n",
    "final_enriched_games_df_records = []\n",
    "for row in playable_games_df.itertuples():\n",
    "\n",
    "    # Convert the row into a dictionary\n",
    "    cur_row_data = row._asdict()\n",
    "    game_id = cur_row_data.get(\"game_id\", None)\n",
    "\n",
    "    # Grab the game's developer\n",
    "    developer = cur_row_data.get(\"developer\", None)\n",
    "    if pd.isna(developer):\n",
    "        developer = steam_details_dict.get(game_id, {}).get(\"developer\", None)\n",
    "\n",
    "    # Add any AI-generated text to the descriptions_text\n",
    "    descriptions = cur_row_data.get(\"description_texts\", [])\n",
    "    ai_search_summary = game_search_results_dict.get(game_id, {}).get(\n",
    "        \"description\", None\n",
    "    )\n",
    "    if pd.notna(ai_search_summary):\n",
    "        descriptions.append(\n",
    "            {\n",
    "                \"source\": \"ai_search_summary\",\n",
    "                \"text\": ai_search_summary,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Grab the proper header image\n",
    "    header_image = cur_row_data.get(\"header_image\", None)\n",
    "    if pd.isna(header_image):\n",
    "        header_image = original_games_dict.get(game_id, {}).get(\n",
    "            \"header_image_url\", None\n",
    "        )\n",
    "    if pd.isna(header_image):\n",
    "        header_image = steam_details_dict.get(game_id, {}).get(\"image_address\", None)\n",
    "\n",
    "    # Determine the list of genres and tags\n",
    "    genres_and_tags = []\n",
    "    if cur_row_data.get(\"genres\", None) is not None:\n",
    "        genres_and_tags.extend(cur_row_data.get(\"genres\", []))\n",
    "    if isinstance(steam_details_dict.get(game_id, {}).get(\"tags\", None), list):\n",
    "        genres_and_tags.extend(steam_details_dict.get(game_id, {}).get(\"tags\", []))\n",
    "    if isinstance(game_search_results_dict.get(game_id, {}).get(\"genres\", None), list):\n",
    "        genres_and_tags.extend(\n",
    "            game_search_results_dict.get(game_id, {}).get(\"genres\", [])\n",
    "        )\n",
    "    # Remove duplicates\n",
    "    genres_and_tags = list(set(genres_and_tags))\n",
    "\n",
    "    # Create the list of media\n",
    "    media = []\n",
    "    if isinstance(steam_details_dict.get(game_id, {}).get(\"image_links\", None), list):\n",
    "        for img_link in steam_details_dict.get(game_id, {}).get(\"image_links\", []):\n",
    "            media.append({\"type\": \"image\", \"source\": \"steam\", \"url\": img_link})\n",
    "    if isinstance(steam_details_dict.get(game_id, {}).get(\"video_link\", None), str):\n",
    "        media.append(\n",
    "            {\n",
    "                \"type\": \"video\",\n",
    "                \"source\": \"steam\",\n",
    "                \"url\": steam_details_dict.get(game_id, {}).get(\"video_link\", None),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Determine any links associated with the game\n",
    "    links = [\n",
    "        {\n",
    "            \"title\": \"Google Search for Game\",\n",
    "            \"url\": f\"https://www.google.com/search?q={cur_row_data.get('title', '')} {developer or ''}\",\n",
    "        }\n",
    "    ]\n",
    "    if isinstance(\n",
    "        game_search_results_dict.get(game_id, {}).get(\"web_search_results\", None), list\n",
    "    ):\n",
    "        for search_result in game_search_results_dict.get(game_id, {}).get(\n",
    "            \"web_search_results\", []\n",
    "        ):\n",
    "            links.append(\n",
    "                {\n",
    "                    \"title\": search_result[0],\n",
    "                    \"url\": search_result[1],\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Deduplicate the descriptions by source\n",
    "    final_desc = []\n",
    "    seen_sources = set()\n",
    "    for desc in descriptions:\n",
    "        if desc[\"source\"] not in seen_sources:\n",
    "            seen_sources.add(desc[\"source\"])\n",
    "            final_desc.append(desc)\n",
    "    descriptions = final_desc\n",
    "\n",
    "    # Start the data dictionary\n",
    "    cur_row_data = {\n",
    "        \"id\": cur_row_data.get(\"game_id\", None),\n",
    "        \"name\": cur_row_data.get(\"title\", None),\n",
    "        \"snappy_summary\": game_search_results_dict.get(game_id, {}).get(\n",
    "            \"snappy_summary\", None\n",
    "        ),\n",
    "        \"description_texts\": descriptions,\n",
    "        \"platforms\": game_search_results_dict.get(game_id, {}).get(\"platforms\", None),\n",
    "        \"developer\": developer,\n",
    "        \"exhibitor\": cur_row_data.get(\"exhibitor_name\", None),\n",
    "        \"booth_number\": cur_row_data.get(\"booth_number\", None),\n",
    "        \"header_image_url\": header_image,\n",
    "        \"steam_link\": steam_details_dict.get(game_id, {}).get(\"steam_url\", None),\n",
    "        \"genres_and_tags\": genres_and_tags,\n",
    "        \"media\": media,\n",
    "        \"released\": game_search_results_dict.get(game_id, {}).get(\"released\", None),\n",
    "        \"release_time\": game_search_results_dict.get(game_id, {}).get(\n",
    "            \"release_time\", None\n",
    "        ),\n",
    "        \"links\": links,\n",
    "    }\n",
    "\n",
    "    # Append the data dictionary\n",
    "    final_enriched_games_df_records.append(cur_row_data)\n",
    "\n",
    "# Make the DataFrame\n",
    "final_enriched_games_df = pd.DataFrame.from_records(final_enriched_games_df_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I'm going to save this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_enriched_games_df.to_json(\n",
    "    \"data/final_enriched_games_data.json\", orient=\"records\", indent=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want to reload it below, I can:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the final_enriched_games_df\n",
    "final_enriched_games_df = pd.read_json(\"data/final_enriched_games_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_enriched_games_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
