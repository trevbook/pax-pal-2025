{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Adding Missing Games**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will help to set up the rest of the notebook. \n",
    "\n",
    "I'll start by configuring the kernel that's running this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/thubbard/Documents/personal/programming/pax-pal-2025/experiments\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the cwd\n",
    "%cd ..\n",
    "\n",
    "# Enable the autoreload module\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load the environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'm going to import the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# Project-specific imports\n",
    "from utils.openai import generate_completions_in_parallel\n",
    "from utils.miscellaneous import get_consistent_hash\n",
    "\n",
    "# Set up the OpenAI client\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p0/6dyp2b_d72z_d772nvm0y6tc0000gn/T/ipykernel_92191/1051968061.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  playable_games_df = pd.read_json(\"data/final_enriched_games_data.json\")\n",
      "/var/folders/p0/6dyp2b_d72z_d772nvm0y6tc0000gn/T/ipykernel_92191/1051968061.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  playable_games_df = pd.read_json(\"data/final_enriched_games_data.json\")\n",
      "/var/folders/p0/6dyp2b_d72z_d772nvm0y6tc0000gn/T/ipykernel_92191/1051968061.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  playable_games_df = pd.read_json(\"data/final_enriched_games_data.json\")\n"
     ]
    }
   ],
   "source": [
    "playable_games_df = pd.read_json(\"data/final_enriched_games_data.json\")\n",
    "exhibitor_details_df = pd.read_json(\"data/exhibitor_details.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Exhibitor Details for Mentions of Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the developer prompt & output format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exhibitor_details_scraping_developer_prompt = \"\"\"# Role\n",
    "You're a digital assistant that loves responding in JSON. You specialize in information extraction tasks. \n",
    "\n",
    "# Task\n",
    "The user will provide you with the description of an exhibitor at a video game convention.\n",
    "\n",
    "You're aiming to extract any explicit mentions of specific games within this description. \n",
    "\n",
    "Games must have a title, and (hopefully) will have some descriptive text surrounding them. \n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class IdentifiedGame(BaseModel):\n",
    "    title: str\n",
    "    description: Optional[str] = None\n",
    "    mentions_playable_at_convention: bool = Field(\n",
    "        ...,\n",
    "        description=\"Whether the description mentions that the game is playable at the convention\",\n",
    "    )\n",
    "\n",
    "\n",
    "class GameIdentificationResults(BaseModel):\n",
    "    games: List[IdentifiedGame]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll prepare data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exhibitor_name_to_markdown_prompt = {}\n",
    "for row in exhibitor_details_df.itertuples():\n",
    "    exhibitor_name_to_markdown_prompt[row.name] = f\"# {row.name}\\n\\n{row.description}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I'll run the prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Completions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 324/324 [00:38<00:00,  8.36it/s]\n"
     ]
    }
   ],
   "source": [
    "exhibitor_details_scraping_completions, exhibitor_details_scraping_cost = (\n",
    "    generate_completions_in_parallel(\n",
    "        message_format_pairs=[\n",
    "            (\n",
    "                [\n",
    "                    {\n",
    "                        \"role\": \"developer\",\n",
    "                        \"content\": exhibitor_details_scraping_developer_prompt,\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": markdown_prompt},\n",
    "                ],\n",
    "                GameIdentificationResults,\n",
    "            )\n",
    "            for exhibitor_name, markdown_prompt in exhibitor_name_to_markdown_prompt.items()\n",
    "        ],\n",
    "        gpt_model=\"gpt-4.1-mini\",\n",
    "        show_progress=True,\n",
    "        max_parallel_requests=32,\n",
    "        return_completion_costs=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I'll parse the completions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exhibitor_names_list = [\n",
    "    exhibitor_name\n",
    "    for exhibitor_name, markdown_prompt in exhibitor_name_to_markdown_prompt.items()\n",
    "]\n",
    "newly_scraped_exhibitor_games_df_records = []\n",
    "for idx, completion in enumerate(exhibitor_details_scraping_completions):\n",
    "    cur_exhibitor_name = exhibitor_names_list[idx]\n",
    "    identified_games = completion.choices[0].message.parsed.games\n",
    "    if len(identified_games) > 0:\n",
    "        for identified_game in identified_games:\n",
    "            newly_scraped_exhibitor_games_df_records.append(\n",
    "                {\n",
    "                    \"exhibitor_name\": cur_exhibitor_name,\n",
    "                    \"game_name\": identified_game.title,\n",
    "                    \"game_description\": identified_game.description,\n",
    "                    \"mentions_playable_at_convention\": identified_game.mentions_playable_at_convention,\n",
    "                }\n",
    "            )\n",
    "\n",
    "newly_scraped_exhibitor_games_df = pd.DataFrame(\n",
    "    newly_scraped_exhibitor_games_df_records\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up: I'm going to remove any games that've already been identified in previous scraping attempts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def alphanum_only(s):\n",
    "    return re.sub(r\"[^a-zA-Z0-9]\", \"\", s)\n",
    "\n",
    "\n",
    "previously_identified_game_names_set = (\n",
    "    playable_games_df[\"name\"]\n",
    "    .apply(lambda name: alphanum_only(str(name).lower()))\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "newly_identified_exhibitor_games_df = newly_scraped_exhibitor_games_df.copy()\n",
    "newly_identified_exhibitor_games_df[\"merge_key\"] = newly_identified_exhibitor_games_df[\n",
    "    \"game_name\"\n",
    "].apply(lambda name: alphanum_only(str(name).lower()))\n",
    "\n",
    "newly_identified_exhibitor_games_df = newly_identified_exhibitor_games_df[\n",
    "    ~newly_identified_exhibitor_games_df[\"merge_key\"].isin(\n",
    "        previously_identified_game_names_set\n",
    "    )\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Internet for Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"# Role\n",
    "You're a digital assistant helping to identify information about games. \n",
    "\n",
    "# Task\n",
    "Search the Internet for information about games provided by users. Synthesize the game's name, description, genres, release date, platforms, and Steam page link.\n",
    "\n",
    "Return information about the search process, including visited URLs and a summary of your findings.\n",
    "\n",
    "# Guidelines\n",
    "- You MUST use the web search tool to find information about the game. \n",
    "- ONLY identify information about the specific game provided. \n",
    "- You ought to aim to find at least three sources for each game. You should prefer authoritative sources (e.g., Wikipedia, Steam, the game's official website) to gather information, but you can also use reviews / blogs / features to understand more. \n",
    "- Return None for the `game_info` field if you can't identify the specific game (or if you're unsure about the identification).\n",
    "- Some of these games may be in-development, so information could be limited; try your best!\n",
    "- For header image URLs - if you've found the Steam link, then they can typically be found at https://cdn.akamai.steamstatic.com/steam/apps/[STEAM_GAME_ID]/header.jpg\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class GameInfo(BaseModel):\n",
    "    game_name: str = Field(..., description=\"The name of the game.\")\n",
    "    released: bool = Field(\n",
    "        ..., description=\"Whether the game has been released (True) or not (False).\"\n",
    "    )\n",
    "    release_year: Optional[int] = Field(\n",
    "        ...,\n",
    "        description=\"The year the game was / will be released, or `None` if this info isn't available\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        ...,\n",
    "        description=\"A paragraph-long description summarizing gameplay, story, aesthetics, and unique features, written in Wikipedia style.\",\n",
    "    )\n",
    "    genres: Optional[List[str]] = Field(..., description=\"A list of genres\")\n",
    "    snappy_summary: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"A short, tagline-like summary (max 10 words) highlighting genre and unique appeal.\",\n",
    "    )\n",
    "    platforms: Optional[List[str]] = Field(\n",
    "        None,\n",
    "        description=\"Platforms available: PlayStation, Xbox, Nintendo Switch, PC, Mobile, or Tabletop\",\n",
    "    )\n",
    "    steam_link: Optional[str] = Field(\n",
    "        None, description=\"Direct URL to the game's Steam page.\"\n",
    "    )\n",
    "    header_image_url: Optional[str] = Field(\n",
    "        None, description=\"URL to a header image for the game.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class GameSearchResults(BaseModel):\n",
    "    web_search_summary: str = Field(\n",
    "        ..., description=\"Summary of whether platform and Steam info were found.\"\n",
    "    )\n",
    "    web_search_results: List[List[str]] = Field(\n",
    "        ...,\n",
    "        description=\"A list of all of the websites visited, where each tuple contains a webpage title and URL.\",\n",
    "    )\n",
    "    correctly_identified_game: bool = Field(\n",
    "        ..., description=\"Whether the game was correctly identified.\"\n",
    "    )\n",
    "    game_info: Optional[GameInfo] = Field(\n",
    "        None,\n",
    "        description=\"Found game info, if `correctly_identified_game` is True. Otherwise, None.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergekey_to_markdown_prompt = {}\n",
    "for row in newly_identified_exhibitor_games_df.itertuples():\n",
    "    mergekey_to_markdown_prompt[row.merge_key] = (\n",
    "        f\"**Exhibitor:** {row.exhibitor_name}\\n\\n**Game Name: **{row.game_name}**\\n\\n**Description:** {row.game_description}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating completions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing games:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 267/323 [03:44<02:41,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing persona3portable: 1 validation error for GameSearchResults\n",
      "  Invalid JSON: EOF while parsing a string at line 1 column 2723 [type=json_invalid, input_value='{\"web_search_summary\":\"P...d1d1d1d1d1d1d1d1d1d1d1 ', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing games: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 323/323 [04:27<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "game_search_results_list = []\n",
    "\n",
    "\n",
    "def process_game(merge_key, markdown_prompt):\n",
    "    try:\n",
    "        # Assuming user_prompt is constructed using the markdown_prompt\n",
    "        current_user_prompt = markdown_prompt  # Modify this if needed to match your user_prompt construction\n",
    "\n",
    "        response = openai_client.responses.parse(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            tools=[{\"type\": \"web_search_preview\", \"search_context_size\": \"low\"}],\n",
    "            input=[\n",
    "                {\n",
    "                    \"role\": \"developer\",\n",
    "                    \"content\": developer_prompt,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": current_user_prompt},\n",
    "            ],\n",
    "            text_format=GameSearchResults,\n",
    "            tool_choice={\"type\": \"web_search_preview\"},\n",
    "        )\n",
    "\n",
    "        # Sleep for 1 second (to avoid rate-limiting)\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Create result dictionary\n",
    "        cur_row_dict = {\n",
    "            \"merge_key\": merge_key,\n",
    "            \"web_search_summary\": response.output_parsed.web_search_summary,\n",
    "            \"web_search_results\": response.output_parsed.web_search_results,\n",
    "            \"correctly_identified_game\": response.output_parsed.correctly_identified_game,\n",
    "        } | (\n",
    "            response.output_parsed.game_info.model_dump()\n",
    "            if response.output_parsed.game_info\n",
    "            else {}\n",
    "        )\n",
    "\n",
    "        return cur_row_dict\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {merge_key}: {e}\")\n",
    "\n",
    "        return {\n",
    "            \"merge_key\": merge_key,\n",
    "            \"web_search_summary\": None,\n",
    "            \"web_search_results\": None,\n",
    "            \"correctly_identified_game\": False,\n",
    "        }\n",
    "\n",
    "\n",
    "# Run processing in parallel with 8 workers\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    # Create a list of futures\n",
    "    futures = [\n",
    "        executor.submit(process_game, merge_key, markdown_prompt)\n",
    "        for merge_key, markdown_prompt in list(mergekey_to_markdown_prompt.items())\n",
    "    ]\n",
    "\n",
    "    # Manually create progress bar ðŸ”„Ã\n",
    "    progress_bar = tqdm.tqdm(total=len(futures), desc=\"Processing games\")\n",
    "\n",
    "    # Process results as they complete\n",
    "    for future in futures:\n",
    "        result = future.result()\n",
    "        game_search_results_list.append(result)\n",
    "        # Update progress bar after each result\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Close the progress bar when done\n",
    "    progress_bar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I need to parse these results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_search_results_df = pd.DataFrame.from_records(game_search_results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Newly Found Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_game_search_results_df = (\n",
    "    game_search_results_df.copy()\n",
    "    .merge(\n",
    "        newly_identified_exhibitor_games_df[[\"merge_key\", \"exhibitor_name\"]],\n",
    "        on=\"merge_key\",\n",
    "    )\n",
    "    .merge(\n",
    "        exhibitor_details_df[[\"name\", \"booth\"]].rename(\n",
    "            columns={\"name\": \"exhibitor_name\"}\n",
    "        ),\n",
    "        on=[\"exhibitor_name\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Remove tabletop\n",
    "filtered_game_search_results_df = filtered_game_search_results_df[\n",
    "    filtered_game_search_results_df[\"platforms\"].apply(\n",
    "        lambda platforms_list: (\n",
    "            False\n",
    "            if (not isinstance(platforms_list, list))\n",
    "            else (False if \"Tabletop\" in platforms_list else True)\n",
    "        )\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "# Remove any where the game wasn't correctly identified\n",
    "filtered_game_search_results_df = filtered_game_search_results_df[\n",
    "    filtered_game_search_results_df[\"correctly_identified_game\"]\n",
    "].copy()\n",
    "\n",
    "# Remove any released in 2023 or earlier\n",
    "filtered_game_search_results_df = filtered_game_search_results_df[\n",
    "    filtered_game_search_results_df[\"release_year\"].apply(\n",
    "        lambda year: True if (year is None or year >= 2024) else False\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "# Remove any already identified\n",
    "filtered_game_search_results_df = filtered_game_search_results_df[\n",
    "    ~filtered_game_search_results_df[\"game_name\"].apply(\n",
    "        lambda name: alphanum_only(name).lower()\n",
    "        in playable_games_df[\"name\"]\n",
    "        .apply(lambda name: alphanum_only(str(name).lower()))\n",
    "        .unique()\n",
    "    )\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'm going to filter out any games whose Steam details weren't correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:05<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from utils.miscellaneous import extract_steam_game_info\n",
    "\n",
    "# Create a list of flags indicating if the game wasn't found on Steam or if extraction was successful\n",
    "steam_extraction_success = []\n",
    "for row in tqdm(list(filtered_game_search_results_df.itertuples())):\n",
    "    # True if no Steam link exists (wasn't found on Steam to begin with)\n",
    "    if pd.isna(row.steam_link):\n",
    "        steam_extraction_success.append(True)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Make a request to the Steam page\n",
    "        response = requests.get(row.steam_link, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            # Extract game information - if we get here, extraction was successful\n",
    "            game_info = extract_steam_game_info(response.text)\n",
    "            if game_info.get(\"name\", None) is None:\n",
    "                # If the game name is None, it means we couldn't extract the game info\n",
    "                steam_extraction_success.append(False)\n",
    "            else:\n",
    "                # Check if the game name matches the expected name\n",
    "                if alphanum_only(game_info[\"name\"].lower()) != row.merge_key:\n",
    "                    # If the names don't match, mark as unsuccessful\n",
    "                    steam_extraction_success.append(False)\n",
    "                else:\n",
    "                    # Otherwise, mark as successful\n",
    "                    steam_extraction_success.append(True)\n",
    "            # Sleep to avoid rate limiting\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            # Failed to get a valid response\n",
    "            steam_extraction_success.append(False)\n",
    "    except requests.exceptions.RequestException:\n",
    "        # Request failed\n",
    "        steam_extraction_success.append(False)\n",
    "\n",
    "# Add the success flag to the dataframe\n",
    "filtered_game_search_results_df[\"steam_extraction_success\"] = steam_extraction_success\n",
    "\n",
    "# Filter to only include games where extraction succeeded or no Steam link existed\n",
    "filtered_game_search_results_df = filtered_game_search_results_df[\n",
    "    filtered_game_search_results_df[\"steam_extraction_success\"]\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Newly Found Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_playable_games_df_records = []\n",
    "for row in filtered_game_search_results_df.itertuples():\n",
    "    new_playable_games_df_records.append(\n",
    "        {\n",
    "            \"id\": get_consistent_hash(row.game_name),\n",
    "            \"genres_and_tags\": row.genres,\n",
    "            \"platforms\": row.platforms,\n",
    "            \"name\": row.game_name,\n",
    "            \"snappy_summary\": row.snappy_summary,\n",
    "            \"description_texts\": [\n",
    "                {\"source\": \"ai_search_summary\", \"text\": row.description}\n",
    "            ],\n",
    "            \"developer\": row.exhibitor_name,\n",
    "            \"exhibitor\": row.exhibitor_name,\n",
    "            \"booth_number\": row.booth,\n",
    "            \"header_image_url\": row.header_image_url,\n",
    "            \"steam_link\": row.steam_link,\n",
    "            \"media\": [],\n",
    "            \"released\": row.released,\n",
    "            \"release_time\": row.release_year,\n",
    "            \"links\": [\n",
    "                {\n",
    "                    \"title\": \"Google Search for Game\",\n",
    "                    \"url\": f\"https://www.google.com/search?q={row.game_name + ' ' + row.exhibitor_name}\",\n",
    "                }\n",
    "            ]\n",
    "            + [\n",
    "                {\"title\": link_tuple[0], \"url\": link_tuple[1]}\n",
    "                for link_tuple in row.web_search_results\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "new_playable_games_df = pd.DataFrame(new_playable_games_df_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Data\n",
    "Finally, I'm going to save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_playable_games_df = pd.concat(\n",
    "    [playable_games_df, new_playable_games_df]\n",
    ").drop_duplicates(subset=[\"name\"], keep=\"first\")\n",
    "\n",
    "final_playable_games_df.to_json(\n",
    "    \"data/extra_final_enriched_games_data.json\", orient=\"records\", indent=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
